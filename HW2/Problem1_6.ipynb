{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Impact of different number of layers, different activation functions and optimization on learning): \n",
    "The code logistic_regression_multi_layer.ipynb is a 2-layer logistic regression. The goal is to extend it to 4- & 6-layer logistic regression with different neurons and activation function for each layer utilizing different optimization routine to assess their impact on accuracy.\n",
    "- (6) 6 layers all sigmoid\n",
    "- In all those cases, what is the exact number of parameters we are trying to learn? Assess and conclude\n",
    "- 784$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$10 + 10 = 49960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-1-af67203b0711>:9: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#load MNIST dataset \n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "learning_rate = 0.05\n",
    "training_epochs = 100\n",
    "batch_size = 50\n",
    "display_step = 10\n",
    "\n",
    "#Network Architecture\n",
    "# -----------------------------------------\n",
    "# Five hidden layers\n",
    "# ------------------------------------------\n",
    "# number of neurons in layer 1\n",
    "n_hidden_1 = 50\n",
    "# number of neurons in layer 2\n",
    "n_hidden_2 = 50\n",
    "# number of neurons in layer 3\n",
    "n_hidden_3 = 50\n",
    "# number of neurons in layer 4\n",
    "n_hidden_4 = 50\n",
    "# number of neurons in layer 5\n",
    "n_hidden_5 = 50\n",
    "\n",
    "#MNIST data image of shape 28*28=784\n",
    "input_size = 784\n",
    "\n",
    "# 0-9 digits recognition (labels)\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape of the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    # comes from the study by He et al. for ReLU layers\n",
    "    w_std = (2.0/weight_shape[0])**0.5\n",
    "    #print(weight_shape[0])\n",
    "    #w_std = 0.5;\n",
    "\n",
    "    #initialization of the weights\n",
    "    #you can try either\n",
    "    w_0 = tf.random_normal_initializer(stddev=w_std)\n",
    "    #w_0 = tf.random_uniform_initializer(minval=-1,maxval=1)\n",
    "\n",
    "    b_0 = tf.constant_initializer(value=0)\n",
    "    \n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_0)\n",
    "    b = tf.get_variable(\"b\", bias_shape,   initializer=b_0)\n",
    "    \n",
    "    #print('Weight Matrix:', W)\n",
    "    #print('Bias Vector:', b)\n",
    "    # sigmoid activation\n",
    "    return tf.nn.sigmoid(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    \"\"\"\n",
    "    define the whole network (6 hidden layers + output layers)\n",
    "    input:\n",
    "        - a batch of pictures \n",
    "        (input shape = (batch_size*image_size))\n",
    "    output:\n",
    "        - a batch vector corresponding to the logits predicted by the network\n",
    "        (output shape = (batch_size*output_size)) \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_layer_1\"):\n",
    "        hidden_1 = layer(x, [input_size, n_hidden_1], [n_hidden_1])\n",
    "        print([input_size, n_hidden_1])\n",
    "     \n",
    "    with tf.variable_scope(\"hidden_layer_2\"):\n",
    "        hidden_2 = layer(hidden_1, [n_hidden_1, n_hidden_2], [n_hidden_2])\n",
    "        print([n_hidden_1, n_hidden_2])\n",
    "\n",
    "    with tf.variable_scope(\"hidden_layer_3\"):\n",
    "        hidden_3 = layer(hidden_2, [n_hidden_2, n_hidden_3], [n_hidden_3])\n",
    "        print([n_hidden_2, n_hidden_3])\n",
    "        \n",
    "    with tf.variable_scope(\"hidden_layer_4\"):\n",
    "        hidden_4 = layer(hidden_3, [n_hidden_3, n_hidden_4], [n_hidden_4])\n",
    "        print([n_hidden_3, n_hidden_4])\n",
    "\n",
    "    with tf.variable_scope(\"hidden_layer_5\"):\n",
    "        hidden_5 = layer(hidden_4, [n_hidden_4, n_hidden_5], [n_hidden_5])\n",
    "        print([n_hidden_4, n_hidden_5])\n",
    "     \n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_5, [n_hidden_5, output_size], [output_size])\n",
    "        print([n_hidden_5, output_size])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_1(output, y):\n",
    "    \"\"\"\n",
    "    computes the average error per data sample \n",
    "    by computing the cross-entropy loss over a minibatch\n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    dot_product = y * tf.log(output)\n",
    "    \n",
    "    #tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "    xentropy = -tf.reduce_sum(dot_product, 1)\n",
    "    \n",
    "    #tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_2(output, y):\n",
    "    \"\"\"\n",
    "    Computes softmax cross entropy between logits and labels and then the loss \n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #mean square error\n",
    "    #loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-output)))\n",
    "    \n",
    "    #Computes softmax cross entropy between logits and labels.\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    # tf.train.AdamOptimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -y: true value for the validation set\n",
    "    output:\n",
    "        - accuracy: accuracy on the validation set (scalar between 0 and 1)\n",
    "    \"\"\"\n",
    "    #correct prediction is a binary vector which equals one when the output and y match\n",
    "    #otherwise the vector equals 0\n",
    "    #tf.cast: change the type of a tensor into another one (改变张量数据类型的转换函数)\n",
    "    #then, by taking the mean of the tensor, we directly have the average score, so the accuracy\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 50]\n",
      "[50, 50]\n",
      "[50, 50]\n",
      "[50, 50]\n",
      "[50, 50]\n",
      "[50, 10]\n",
      "WARNING:tensorflow:From <ipython-input-5-ca3425cd9455>:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 000 cost function= 2.2022725  Validation Error: 0.8375999927520752\n",
      "Epoch: 010 cost function= 2.3633841  Validation Error: 0.9024000018835068\n",
      "Epoch: 020 cost function= 2.3025850  Validation Error: 0.8874000012874603\n",
      "Epoch: 030 cost function= 2.2321970  Validation Error: 0.8147999942302704\n",
      "Epoch: 040 cost function= 2.3488048  Validation Error: 0.8874000012874603\n",
      "Epoch: 050 cost function= 2.3488048  Validation Error: 0.8874000012874603\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 060 cost function= 2.3488048  Validation Error: 0.8874000012874603\n",
      "Epoch: 070 cost function= 2.3488048  Validation Error: 0.8874000012874603\n",
      "Epoch: 080 cost function= 2.3488048  Validation Error: 0.8874000012874603\n",
      "Epoch: 090 cost function= 2.3488048  Validation Error: 0.8874000012874603\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.1135\n",
      "Execution time (seconds) was 456.965\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #please, make sure you changed for your own path \n",
    "    log_files_path = 'D:/JupyterNotebook/IEOR_4742/HW2/logs/'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        with tf.variable_scope(\"multi_layer\"):\n",
    "            #neural network definition \n",
    "            \n",
    "            #the input variables are first defined as placeholder \n",
    "            #a placeholder is a variable/data which will be assigned later \n",
    "            #image vector & label\n",
    "            x = tf.placeholder(\"float\", [None, input_size])   # MNIST data image of shape 28*28=784\n",
    "            y = tf.placeholder(\"float\", [None, output_size])  # 0-9 digits recognition\n",
    "\n",
    "            #the network is defined using the inference function defined above in the code\n",
    "            output = inference(x)\n",
    "\n",
    "            cost = loss_2(output, y)\n",
    "            \n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            train_op = training(cost, global_step)\n",
    "            #train_op = training(cost, global_step=None)\n",
    "            \n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op = evaluate(output, y)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "    \n",
    "            #save and restore variables to and from checkpoints.\n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #\n",
    "            summary_writer = tf.summary.FileWriter(log_files_path+'multi_layer/', sess.graph)\n",
    "        \n",
    "            #initialization of all the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "        \n",
    "            #will work with this later\n",
    "            #saver.restore(sess, log_files_path+'multi_layer/model-checkpoint-66000')\n",
    "            \n",
    "            loss_trace = []\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "\n",
    "                    minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "                    loss_trace.append(1-accuracy)    \n",
    "                    print(\"Epoch:\", '%03d' % epoch, \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "                        \n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    saver.save(sess, log_files_path + 'multi_layer/model-checkpoint', global_step=global_step)\n",
    "                        \n",
    "            print(\"Optimization Finished!\")\n",
    "            #accuracy evaluated with the whole test dataset\n",
    "            accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            print(\"Test Accuracy:\", accuracy)\n",
    "                    \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Execution time (seconds) was %0.3f' % elapsed_time)\n",
    "            \n",
    "            # Visualization of the results\n",
    "            # loss function\n",
    "            plt.plot(loss_trace)\n",
    "            plt.title('Cross Entropy Loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
