{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Impact of different number of layers, different activation functions and optimization on learning): \n",
    "The code logistic_regression_multi_layer.ipynb is a 2-layer logistic regression. The goal is to extend it to 4- & 6-layer logistic regression with different neurons and activation function for each layer utilizing different optimization routine to assess their impact on accuracy.\n",
    "- (1) 1st layer: sigmoid, 2nd layer: tanh, 3rd layer: reLU, 4th layer: sigmoid, 5th layer: leaky reLU, 6th layer: tanh\n",
    "- In all those cases, what is the exact number of parameters we are trying to learn? Assess and conclude\n",
    "- 784$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$10 + 10 = 49960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-1-af67203b0711>:9: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#load MNIST dataset \n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "learning_rate = 0.05\n",
    "training_epochs = 100\n",
    "batch_size = 50\n",
    "display_step = 10\n",
    "\n",
    "#Network Architecture\n",
    "# -----------------------------------------\n",
    "# Five hidden layers\n",
    "# ------------------------------------------\n",
    "# number of neurons in layer 1\n",
    "n_hidden_1 = 50\n",
    "# number of neurons in layer 2\n",
    "n_hidden_2 = 50\n",
    "# number of neurons in layer 3\n",
    "n_hidden_3 = 50\n",
    "# number of neurons in layer 4\n",
    "n_hidden_4 = 50\n",
    "# number of neurons in layer 5\n",
    "n_hidden_5 = 50\n",
    "\n",
    "#MNIST data image of shape 28*28=784\n",
    "input_size = 784\n",
    "\n",
    "# 0-9 digits recognition (labels)\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape, activation='relu'):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape of the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    # comes from the study by He et al. for ReLU layers\n",
    "    w_std = (2.0/weight_shape[0])**0.5\n",
    "    #print(weight_shape[0])\n",
    "    #w_std = 0.5;\n",
    "\n",
    "    #initialization of the weights\n",
    "    #you can try either\n",
    "    #w_0 = tf.random_uniform_initializer(minval=-1,maxval=1)\n",
    "    w_0 = tf.random_normal_initializer(stddev=w_std)\n",
    "    b_0 = tf.constant_initializer(value=0)\n",
    "    \n",
    "    #tf.get_variable(name,  shape, initializer), 用于创建变量，必须指定变量名name, name不能相同\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_0)\n",
    "    b = tf.get_variable(\"b\", bias_shape,   initializer=b_0)\n",
    "    print('Weight Matrix:', W)\n",
    "    print('Bias Vector:', b)\n",
    "\n",
    "    # different activation functions\n",
    "    if activation=='relu':\n",
    "        return tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    elif activation=='leaky_relu':\n",
    "        return tf.nn.leaky_relu(tf.matmul(x, W) + b)\n",
    "    elif activation=='sigmoid':\n",
    "        return tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "    elif activation=='tanh':\n",
    "        return tf.nn.tanh(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    \"\"\"\n",
    "    define the whole network (5 hidden layers + output layers)\n",
    "    input:\n",
    "        - a batch of pictures \n",
    "        (input shape = (batch_size*image_size))\n",
    "    output:\n",
    "        - a batch vector corresponding to the logits predicted by the network\n",
    "        (output shape = (batch_size*output_size)) \n",
    "    \"\"\"\n",
    "\n",
    "    #tf.variable_scope可以让变量有相同的命名，包括tf.get_variable得到的变量，还有tf.Variable得到的变量\n",
    "    with tf.variable_scope(\"hidden_layer_1\"):\n",
    "        hidden_1 = layer(x, [input_size, n_hidden_1], [n_hidden_1], 'sigmoid')\n",
    "        #print([input_size, n_hidden_1])\n",
    "     \n",
    "    with tf.variable_scope(\"hidden_layer_2\"):\n",
    "        hidden_2 = layer(hidden_1, [n_hidden_1, n_hidden_2], [n_hidden_2], 'tanh')\n",
    "        #print([n_hidden_1, n_hidden_2])\n",
    "\n",
    "    with tf.variable_scope(\"hidden_layer_3\"):\n",
    "        hidden_3 = layer(hidden_2, [n_hidden_2, n_hidden_3], [n_hidden_3], 'relu')\n",
    "        #print([n_hidden_2, n_hidden_3])\n",
    "        \n",
    "    with tf.variable_scope(\"hidden_layer_4\"):\n",
    "        hidden_4 = layer(hidden_3, [n_hidden_3, n_hidden_4], [n_hidden_4], 'sigmoid')\n",
    "        #print([n_hidden_3, n_hidden_4])\n",
    "\n",
    "    with tf.variable_scope(\"hidden_layer_5\"):\n",
    "        hidden_5 = layer(hidden_4, [n_hidden_4, n_hidden_5], [n_hidden_5], 'leaky_relu')\n",
    "        #print([n_hidden_4, n_hidden_5])\n",
    "     \n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_5, [n_hidden_5, output_size], [output_size], 'tanh')\n",
    "        #print([n_hidden_5, output_size])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_1(output, y):\n",
    "    \"\"\"\n",
    "    computes the average error per data sample \n",
    "    by computing the cross-entropy loss over a minibatch\n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    dot_product = y * tf.log(output)\n",
    "    \n",
    "    #tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "    xentropy = -tf.reduce_sum(dot_product, 1)\n",
    "    \n",
    "    #tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_2(output, y):\n",
    "    \"\"\"\n",
    "    Computes softmax cross entropy between logits and labels and then the loss \n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #mean square error\n",
    "    #loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-output)))\n",
    "    \n",
    "    #Computes softmax cross entropy between logits and labels.\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    # tf.train.AdamOptimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -y: true value for the validation set\n",
    "    output:\n",
    "        - accuracy: accuracy on the validation set (scalar between 0 and 1)\n",
    "    \"\"\"\n",
    "    #correct prediction is a binary vector which equals one when the output and y match\n",
    "    #otherwise the vector equals 0\n",
    "    #tf.cast: change the type of a tensor into another one (改变张量数据类型的转换函数)\n",
    "    #then, by taking the mean of the tensor, we directly have the average score, so the accuracy\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_1/W:0' shape=(784, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_1/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_2/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_2/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_3/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_3/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_4/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_4/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_5/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_5/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/output/W:0' shape=(50, 10) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/output/b:0' shape=(10,) dtype=float32_ref>\n",
      "WARNING:tensorflow:From <ipython-input-5-ca3425cd9455>:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 000 cost function= 2.3063161  Validation Error: 0.9024000018835068\n",
      "Epoch: 010 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Epoch: 020 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Epoch: 030 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Epoch: 040 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Epoch: 050 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 060 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Epoch: 070 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Epoch: 080 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Epoch: 090 cost function= 2.3025854  Validation Error: 0.9024000018835068\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.1032\n",
      "Execution time (seconds) was 375.447\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWfklEQVR4nO3df7RdZX3n8fcHAqJAQE1qJQGCSi2xBYRbqqMWlzg2MFZU/AECBcelM6viaBUVFEcaa+m01MFp0ZYqikKliD+GVka0FLDtoHIDBBsQm1IgISgXofwQEQLf+WPvDCc3T5IL3pNzk7xfa52VvZ/97LO/Z+fe8zn7ec45N1WFJEmTbTPqAiRJM5MBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQGjGSPKmJONJ7k9ye5L/k+TFI6zns0ke6utZc1s6xX1PTXLusGucqiQ3J3n5qOvQ5sWA0IyQ5N3AGcAfAM8A9gA+ARy+nv6zNlFpf1RVOw3c9puOO03H3z/NaP6AauSS7AIsBt5eVV+uqp9U1cNV9TdV9d6+z6lJLkxybpJ7geOTPCnJGUlW9bczkjyp7z8nyd8m+fckdyX5hzVPyEnen+S2JPcluTHJIU+g5gVJKslxSW5NcmeSD/bbFgEfAN44eNWR5PIkH03yT8ADwLOS7Jbkor7G5UneOnCMNY/5r/tar06yX7/tvUm+NKmmP01yxhN4LG/tj31XX8tufXuS/M8kdyS5J8l1SX6l33ZYkuv7um5LcuLjPa42A1XlzdtIb8AiYDUwawN9TgUeBl5N98LmyXSh8m3gF4C5wP8FPtL3Pw34c2C7/vYSIMBzgRXAbn2/BcCz13PMzwK/v55tC4AC/rKvZT/gZ8A+A/WeO2mfy4FbgecBs/q6rqC7UtoB2B+YAA6Z9Jhf1/c9Efi3fvmZwE+AXfu+s4A7gAPXU+/NwMsb7S8D7gQOAJ4E/CnwrX7bbwJLgF37c7cP8Mx+2+3AS/rlpwIHjPrnyNv037yC0EzwdODOqlq9kX5XVtVXq+rRqvopcDSwuKruqKoJ4PeAY/u+D9M9ie5Z3dXIP1T3bPYI3RPhwiTbVdXNVfWvGzjmif1VyJrbOZO2/15V/bSqlgJL6YJiQz5bVcv6x/qLwIuB91fVg1V1LfCpgccAsKSqLqyqh4GP0QXJC6rqduBbwOv7fovozuGSjRx/sqOBs6vq6qr6GXAy8MIkC+jO4c7ALwOpqhv649JvW5hkdlXdXVVXP87jajNgQGgm+DEwZwrzCismre8G3DKwfkvfBvDHwHLgG0luSnISQFUtB95F9+r8jiTnrxlSWY/Tq2rXgdtxk7b/cGD5AWCnx/EYdgPuqqr7Jj2Gea3+VfUosHLgMZ4DHNMvHwN8fiPHblnrHFbV/XT/H/Oq6u+BPwPOBH6U5Kwks/uuRwCHAbckuSLJC5/AsTXDGRCaCa4EHqQbPtqQyV89vArYc2B9j76Nqrqvqt5TVc8Cfgt495q5hqr6q6p6cb9vAf/j538IG6211b4KeFqSnQfa9gBuG1jffc1CP4cyv98P4KvAvv28wCuB855AnWudwyQ70l3R3QZQVf+rqg6kGxb7JeC9fftVVXU43fDeV4ELnsCxNcMZEBq5qroH+O/AmUleneQpSbZLcmiSP9rArl8ATkkyN8mc/j7OBUjyyiTPSRLgXrqhpUeSPDfJy/rJ7AeBn/bbptuPgAUbeqdSVa2gmzc5LckOSfYF3sLaT/QHJnltf3X1Lrp5jm/3+z8IXAj8FfDdqrp1IzVt1x9nzW1Wv++bk+zfn5M/AL5TVTcn+bUkv55kO7r5jgfpzuH2SY5Osks/9LXm/GoLY0BoRqiqjwHvBk6hm6hdAZxA9+p0fX4fGAeuA74HXN23AewN/B1wP90Vyieq6nK6+Yc/pJuY/SHdK+APbOAY78van4O4c4oP6Yv9vz9OsqHx+aPoJrxXAV8BPlxV3xzY/r+BNwJ3081NvLZ/Ul7jHOBXmdrw0sV0gbjmdmpVXQp8CPgS3cTzs4Ej+/6z6Sbh76YbhvoxcHq/7Vjg5v4dZf+Vx4a6tAVJN28naaZJcirwnKpa75Nvkj2A7wO/WFX3bqratHXwCkLaTPXDV+8GzjccNAyb6tOokqZRP5n8I7qhn0UjLkdbKIeYJElNDjFJkpq2mCGmOXPm1IIFC0ZdhiRtVpYsWXJnVc1tbdtiAmLBggWMj4+PugxJ2qwkuWV92xxikiQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJahpqQCRZlOTGJMuTnNTYvmeSS5Ncl+TyJPMnbZ+d5LYkfzbMOiVJ6xpaQCTZFjgTOBRYCByVZOGkbqcDn6uqfYHFwGmTtn8EuGJYNUqS1m+YVxAHAcur6qaqegg4Hzh8Up+FwKX98mWD25McCDwD+MYQa5QkrccwA2IesGJgfWXfNmgpcES//Bpg5yRPT7IN8CfAezd0gCRvSzKeZHxiYmKaypYkwXADIo22mrR+InBwkmuAg4HbgNXA7wAXV9UKNqCqzqqqsaoamzt37nTULEnqzRrifa8Edh9Ynw+sGuxQVauA1wIk2Qk4oqruSfJC4CVJfgfYCdg+yf1Vtc5EtyRpOIYZEFcBeyfZi+7K4EjgTYMdkswB7qqqR4GTgbMBqurogT7HA2OGgyRtWkMbYqqq1cAJwCXADcAFVbUsyeIkr+q7vRS4MckP6CakPzqseiRJj0+qJk8LbJ7GxsZqfHx81GVI0mYlyZKqGmtt85PUkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktQ01IBIsijJjUmWJzmpsX3PJJcmuS7J5Unm9+37J7kyybJ+2xuHWackaV1DC4gk2wJnAocCC4Gjkiyc1O104HNVtS+wGDitb38A+O2qeh6wCDgjya7DqlWStK5hXkEcBCyvqpuq6iHgfODwSX0WApf2y5et2V5VP6iqf+mXVwF3AHOHWKskaZJhBsQ8YMXA+sq+bdBS4Ih++TXAzkmePtghyUHA9sC/DqlOSVLDMAMijbaatH4icHCSa4CDgduA1f//DpJnAp8H3lxVj65zgORtScaTjE9MTExf5ZKkoQbESmD3gfX5wKrBDlW1qqpeW1XPBz7Yt90DkGQ28DXglKr6dusAVXVWVY1V1djcuY5ASdJ0GmZAXAXsnWSvJNsDRwIXDXZIMifJmhpOBs7u27cHvkI3gf3FIdYoSVqPoQVEVa0GTgAuAW4ALqiqZUkWJ3lV3+2lwI1JfgA8A/ho3/4G4DeA45Nc29/2H1atkqR1pWrytMDmaWxsrMbHx0ddhiRtVpIsqaqx1jY/SS1JajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqWlKAZHknUlmp/PpJFcnecWwi5Mkjc5UryD+c1XdC7wCmAu8GfjDoVUlSRq5qQZE+n8PAz5TVUsH2iRJW6CpBsSSJN+gC4hLkuwMPDq8siRJozZriv3eAuwP3FRVDyR5Gt0wkyRpCzXVgHghcG1V/STJMcABwMeHV9am9Xt/s4zrV9076jIk6QlZuNtsPvxbz5v2+53qENMngQeS7Ae8D7gF+Ny0VyNJmjGmegWxuqoqyeHAx6vq00mOG2Zhm9IwkleSNndTvYK4L8nJwLHA15JsC2y3sZ2SLEpyY5LlSU5qbN8zyaVJrktyeZL5A9uOS/Iv/W2LCSNJ2lxMNSDeCPyM7vMQPwTmAX+8oR36EDkTOBRYCByVZOGkbqcDn6uqfYHFwGn9vk8DPgz8OnAQ8OEkT51irZKkaTClgOhD4TxglySvBB6sqo3NQRwELK+qm6rqIeB84PBJfRYCl/bLlw1s/03gm1V1V1XdDXwTWDSVWiVJ02OqX7XxBuC7wOuBNwDfSfK6jew2D1gxsL6ybxu0FDiiX34NsHOSp09xX5K8Lcl4kvGJiYmpPBRJ0hRNdYjpg8CvVdVxVfXbdFcHH9rIPq1PWtek9ROBg5NcAxwM3AasnuK+VNVZVTVWVWNz587d2GOQJD0OU30X0zZVdcfA+o/ZeLisBHYfWJ8PrBrsUFWrgNcCJNkJOKKq7kmyEnjppH0vn2KtkqRpMNUriK8nuSTJ8UmOB74GXLyRfa4C9k6yV5LtgSOBiwY7JJmTZE0NJwNn98uXAK9I8tR+cvoVfZskaROZ0hVEVb03yRHAi+iGf86qqq9sZJ/VSU6ge2LfFji7qpYlWQyMV9VFdFcJpyUp4FvA2/t970ryEbqQAVhcVXc9/ocnSXqiUrXO0P5maWxsrMbHx0ddhiRtVpIsqaqx1rYNXkEkuY/G5DDdVURV1expqE+SNANtMCCqaudNVYgkaWbxb1JLkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKahhoQSRYluTHJ8iQnNbbvkeSyJNckuS7JYX37dknOSfK9JDckOXmYdUqS1jW0gEiyLXAmcCiwEDgqycJJ3U4BLqiq5wNHAp/o218PPKmqfhU4EPgvSRYMq1ZJ0rqGeQVxELC8qm6qqoeA84HDJ/UpYHa/vAuwaqB9xySzgCcDDwH3DrFWSdIkwwyIecCKgfWVfdugU4FjkqwELgbe0bdfCPwEuB24FTi9qu6afIAkb0synmR8YmJimsuXpK3bMAMijbaatH4U8Nmqmg8cBnw+yTZ0Vx+PALsBewHvSfKsde6s6qyqGquqsblz505v9ZK0lRtmQKwEdh9Yn89jQ0hrvAW4AKCqrgR2AOYAbwK+XlUPV9UdwD8BY0OsVZI0yTAD4ipg7yR7JdmebhL6okl9bgUOAUiyD11ATPTtL0tnR+AFwPeHWKskaZKhBURVrQZOAC4BbqB7t9KyJIuTvKrv9h7grUmWAl8Ajq+qonv3007AP9MFzWeq6rph1SpJWle65+PN39jYWI2Pj4+6DEnarCRZUlXNIXw/SS1JajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKlpqAGRZFGSG5MsT3JSY/seSS5Lck2S65IcNrBt3yRXJlmW5HtJdhhmrZKktc0a1h0n2RY4E/iPwErgqiQXVdX1A91OAS6oqk8mWQhcDCxIMgs4Fzi2qpYmeTrw8LBqlSSta5hXEAcBy6vqpqp6CDgfOHxSnwJm98u7AKv65VcA11XVUoCq+nFVPTLEWiVJkwwzIOYBKwbWV/Ztg04Fjkmyku7q4R19+y8BleSSJFcneV/rAEnelmQ8yfjExMT0Vi9JW7lhBkQabTVp/Sjgs1U1HzgM+HySbeiGvl4MHN3/+5okh6xzZ1VnVdVYVY3NnTt3equXpK3cMANiJbD7wPp8HhtCWuMtwAUAVXUlsAMwp9/3iqq6s6oeoLu6OGCItUqSJhlmQFwF7J1kryTbA0cCF03qcytwCECSfegCYgK4BNg3yVP6CeuDgeuRJG0yQ3sXU1WtTnIC3ZP9tsDZVbUsyWJgvKouAt4D/GWS36Ubfjq+qgq4O8nH6EKmgIur6mvDqlWStK50z8ebv7GxsRofHx91GZK0WUmypKrGWtv8JLUkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNW0xX7WRZAK45ee4iznAndNUzubOc7E2z8faPB+P2RLOxZ5V1fx7CVtMQPy8koyv7/tItjaei7V5Ptbm+XjMln4uHGKSJDUZEJKkJgPiMWeNuoAZxHOxNs/H2jwfj9miz4VzEJKkJq8gJElNBoQkqWmrD4gki5LcmGR5kpNGXc8oJdk9yWVJbkiyLMk7R13TqCXZNsk1Sf521LWMWpJdk1yY5Pv9z8gLR13TKCX53f735J+TfCHJDqOuabpt1QGRZFvgTOBQYCFwVJKFo61qpFYD76mqfYAXAG/fys8HwDuBG0ZdxAzxceDrVfXLwH5sxeclyTzgvwFjVfUrwLbAkaOtavpt1QEBHAQsr6qbquoh4Hzg8BHXNDJVdXtVXd0v30f3BDBvtFWNTpL5wH8CPjXqWkYtyWzgN4BPA1TVQ1X176OtauRmAU9OMgt4CrBqxPVMu609IOYBKwbWV7IVPyEOSrIAeD7wndFWMlJnAO8DHh11ITPAs4AJ4DP9kNunkuw46qJGpapuA04HbgVuB+6pqm+Mtqrpt7UHRBptW/37fpPsBHwJeFdV3TvqekYhySuBO6pqyahrmSFmAQcAn6yq5wM/AbbaObskT6UbbdgL2A3YMckxo61q+m3tAbES2H1gfT5b4GXi45FkO7pwOK+qvjzqekboRcCrktxMN/T4siTnjrakkVoJrKyqNVeUF9IFxtbq5cC/VdVEVT0MfBn4DyOuadpt7QFxFbB3kr2SbE83yXTRiGsamSShG2O+oao+Nup6RqmqTq6q+VW1gO7n4u+raot7hThVVfVDYEWS5/ZNhwDXj7CkUbsVeEGSp/S/N4ewBU7azxp1AaNUVauTnABcQvcuhLOratmIyxqlFwHHAt9Lcm3f9oGquniENWnmeAdwXv9i6ibgzSOuZ2Sq6jtJLgSupnv33zVsgV+74VdtSJKatvYhJknSehgQkqQmA0KS1GRASJKaDAhJUpMBIc0ASV7qN8ZqpjEgJElNBoT0OCQ5Jsl3k1yb5C/6vxdxf5I/SXJ1kkuTzO377p/k20muS/KV/vt7SPKcJH+XZGm/z7P7u99p4O8tnNd/QlcaGQNCmqIk+wBvBF5UVfsDjwBHAzsCV1fVAcAVwIf7XT4HvL+q9gW+N9B+HnBmVe1H9/09t/ftzwfeRfe3SZ5F98l2aWS26q/akB6nQ4ADgav6F/dPBu6g+zrwv+77nAt8OckuwK5VdUXffg7wxSQ7A/Oq6isAVfUgQH9/362qlf36tcAC4B+H/7CkNgNCmroA51TVyWs1Jh+a1G9D31+zoWGjnw0sP4K/nxoxh5ikqbsUeF2SXwBI8rQke9L9Hr2u7/Mm4B+r6h7g7iQv6duPBa7o/77GyiSv7u/jSUmeskkfhTRFvkKRpqiqrk9yCvCNJNsADwNvp/vjOc9LsgS4h26eAuA44M/7ABj89tNjgb9Isri/j9dvwochTZnf5ir9nJLcX1U7jboOabo5xCRJavIKQpLU5BWEJKnJgJAkNRkQkqQmA0KS1GRASJKa/h/qEd3hNCblawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #please, make sure you changed for your own path \n",
    "    log_files_path = 'D:/JupyterNotebook/IEOR_4742/HW2/logs/'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        with tf.variable_scope(\"multi_layer\"):\n",
    "            #neural network definition \n",
    "            \n",
    "            #the input variables are first defined as placeholder \n",
    "            #a placeholder is a variable/data which will be assigned later \n",
    "            #image vector & label\n",
    "            x = tf.placeholder(\"float\", [None, input_size])   # MNIST data image of shape 28*28=784\n",
    "            y = tf.placeholder(\"float\", [None, output_size])  # 0-9 digits recognition\n",
    "\n",
    "            #the network is defined using the inference function defined above in the code\n",
    "            output = inference(x)\n",
    "\n",
    "            cost = loss_2(output, y)\n",
    "            \n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            train_op = training(cost, global_step)\n",
    "            #train_op = training(cost, global_step=None)\n",
    "            \n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op = evaluate(output, y)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "    \n",
    "            #save and restore variables to and from checkpoints.\n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #\n",
    "            summary_writer = tf.summary.FileWriter(log_files_path+'multi_layer/', sess.graph)\n",
    "        \n",
    "            #initialization of all the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "        \n",
    "            #will work with this later\n",
    "            #saver.restore(sess, log_files_path+'multi_layer/model-checkpoint-66000')\n",
    "            \n",
    "            loss_trace = []\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "\n",
    "                    minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "                    loss_trace.append(1-accuracy)    \n",
    "                    print(\"Epoch:\", '%03d' % epoch, \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "                        \n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    saver.save(sess, log_files_path + 'multi_layer/model-checkpoint', global_step=global_step)\n",
    "                        \n",
    "            print(\"Optimization Finished!\")\n",
    "            #accuracy evaluated with the whole test dataset\n",
    "            accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            print(\"Test Accuracy:\", accuracy)\n",
    "                    \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Execution time (seconds) was %0.3f' % elapsed_time)\n",
    "            \n",
    "            # Visualization of the results\n",
    "            # loss function\n",
    "            plt.plot(loss_trace)\n",
    "            plt.title('Cross Entropy Loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
