{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Impact of different number of layers, different activation functions and optimization on learning): \n",
    "The code logistic_regression_multi_layer.ipynb is a 2-layer logistic regression. The goal is to extend it to 4- & 6-layer logistic regression with different neurons and activation function for each layer utilizing different optimization routine to assess their impact on accuracy.\n",
    "- (1) 1st layer: sigmoid, 2nd layer: tanh, 3rd layer: reLU, 4th layer: sigmoid, 5th layer: leaky reLU, 6th layer: tanh\n",
    "- In all those cases, what is the exact number of parameters we are trying to learn? Assess and conclude\n",
    "- 784$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$10 + 10 = 49960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-1-75954950f2f9>:9: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#load MNIST dataset \n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "learning_rate = 0.05\n",
    "training_epochs = 100\n",
    "batch_size = 50\n",
    "display_step = 10\n",
    "\n",
    "#Network Architecture\n",
    "# -----------------------------------------\n",
    "# Five hidden layers\n",
    "# ------------------------------------------\n",
    "# number of neurons in layer 1\n",
    "n_hidden_1 = 50\n",
    "# number of neurons in layer 2\n",
    "n_hidden_2 = 50\n",
    "# number of neurons in layer 3\n",
    "n_hidden_3 = 50\n",
    "# number of neurons in layer 4\n",
    "n_hidden_4 = 50\n",
    "# number of neurons in layer 5\n",
    "n_hidden_5 = 50\n",
    "\n",
    "#MNIST data image of shape 28*28=784\n",
    "input_size = 784\n",
    "\n",
    "# 0-9 digits recognition (labels)\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape, activation='relu'):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape of the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    # comes from the study by He et al. for ReLU layers\n",
    "    w_std = (2.0/weight_shape[0])**0.5\n",
    "    #print(weight_shape[0])\n",
    "    #w_std = 0.5;\n",
    "\n",
    "    #initialization of the weights\n",
    "    #you can try either\n",
    "    #w_0 = tf.random_uniform_initializer(minval=-1,maxval=1)\n",
    "    w_0 = tf.random_normal_initializer(stddev=w_std)\n",
    "    b_0 = tf.constant_initializer(value=0)\n",
    "    \n",
    "    #tf.get_variable(name,  shape, initializer), 用于创建变量，必须指定变量名name, name不能相同\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_0)\n",
    "    b = tf.get_variable(\"b\", bias_shape,   initializer=b_0)\n",
    "    print('Weight Matrix:', W)\n",
    "    print('Bias Vector:', b)\n",
    "\n",
    "    # different activation functions\n",
    "    if activation=='relu':\n",
    "        return tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    elif activation=='leaky_relu':\n",
    "        return tf.nn.leaky_relu(tf.matmul(x, W) + b)\n",
    "    elif activation=='sigmoid':\n",
    "        return tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "    elif activation=='tanh':\n",
    "        return tf.nn.tanh(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    \"\"\"\n",
    "    define the whole network (5 hidden layers + output layers)\n",
    "    input:\n",
    "        - a batch of pictures \n",
    "        (input shape = (batch_size*image_size))\n",
    "    output:\n",
    "        - a batch vector corresponding to the logits predicted by the network\n",
    "        (output shape = (batch_size*output_size)) \n",
    "    \"\"\"\n",
    "\n",
    "    #tf.variable_scope可以让变量有相同的命名，包括tf.get_variable得到的变量，还有tf.Variable得到的变量\n",
    "    with tf.variable_scope(\"hidden_layer_1\"):\n",
    "        hidden_1 = layer(x, [input_size, n_hidden_1], [n_hidden_1], 'sigmoid')\n",
    "        #print([input_size, n_hidden_1])\n",
    "     \n",
    "    with tf.variable_scope(\"hidden_layer_2\"):\n",
    "        hidden_2 = layer(hidden_1, [n_hidden_1, n_hidden_2], [n_hidden_2], 'tanh')\n",
    "        #print([n_hidden_1, n_hidden_2])\n",
    "\n",
    "    with tf.variable_scope(\"hidden_layer_3\"):\n",
    "        hidden_3 = layer(hidden_2, [n_hidden_2, n_hidden_3], [n_hidden_3], 'relu')\n",
    "        #print([n_hidden_2, n_hidden_3])\n",
    "        \n",
    "    with tf.variable_scope(\"hidden_layer_4\"):\n",
    "        hidden_4 = layer(hidden_3, [n_hidden_3, n_hidden_4], [n_hidden_4], 'sigmoid')\n",
    "        #print([n_hidden_3, n_hidden_4])\n",
    "\n",
    "    with tf.variable_scope(\"hidden_layer_5\"):\n",
    "        hidden_5 = layer(hidden_4, [n_hidden_4, n_hidden_5], [n_hidden_5], 'leaky_relu')\n",
    "        #print([n_hidden_4, n_hidden_5])\n",
    "     \n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_5, [n_hidden_5, output_size], [output_size], 'tanh')\n",
    "        #print([n_hidden_5, output_size])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_1(output, y):\n",
    "    \"\"\"\n",
    "    computes the average error per data sample \n",
    "    by computing the cross-entropy loss over a minibatch\n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    dot_product = y * tf.log(output)\n",
    "    \n",
    "    #tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "    xentropy = -tf.reduce_sum(dot_product, 1)\n",
    "    \n",
    "    #tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_2(output, y):\n",
    "    \"\"\"\n",
    "    Computes softmax cross entropy between logits and labels and then the loss \n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #mean square error\n",
    "    #loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-output)))\n",
    "    \n",
    "    #Computes softmax cross entropy between logits and labels.\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    # tf.train.AdamOptimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -y: true value for the validation set\n",
    "    output:\n",
    "        - accuracy: accuracy on the validation set (scalar between 0 and 1)\n",
    "    \"\"\"\n",
    "    #correct prediction is a binary vector which equals one when the output and y match\n",
    "    #otherwise the vector equals 0\n",
    "    #tf.cast: change the type of a tensor into another one (改变张量数据类型的转换函数)\n",
    "    #then, by taking the mean of the tensor, we directly have the average score, so the accuracy\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_1/W:0' shape=(784, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_1/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_2/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_2/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_3/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_3/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_4/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_4/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/hidden_layer_5/W:0' shape=(50, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/hidden_layer_5/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_layer/output/W:0' shape=(50, 10) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_layer/output/b:0' shape=(10,) dtype=float32_ref>\n",
      "WARNING:tensorflow:From <ipython-input-5-ca3425cd9455>:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 000 cost function= 2.5989401  Validation Error: 0.8874000012874603\n",
      "Epoch: 010 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Epoch: 020 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Epoch: 030 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Epoch: 040 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Epoch: 050 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 060 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Epoch: 070 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Epoch: 080 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Epoch: 090 cost function= 2.5986183  Validation Error: 0.8874000012874603\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.1135\n",
      "Execution time (seconds) was 339.513\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #please, make sure you changed for your own path \n",
    "    log_files_path = 'D:/JupyterNotebook/IEOR_4742/HW2/Problem3/logs/'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        with tf.variable_scope(\"multi_layer\"):\n",
    "            #neural network definition \n",
    "            \n",
    "            #the input variables are first defined as placeholder \n",
    "            #a placeholder is a variable/data which will be assigned later \n",
    "            #image vector & label\n",
    "            x = tf.placeholder(\"float\", [None, input_size])   # MNIST data image of shape 28*28=784\n",
    "            y = tf.placeholder(\"float\", [None, output_size])  # 0-9 digits recognition\n",
    "\n",
    "            #the network is defined using the inference function defined above in the code\n",
    "            output = inference(x)\n",
    "\n",
    "            cost = loss_2(output, y)\n",
    "            \n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            train_op = training(cost, global_step)\n",
    "            #train_op = training(cost, global_step=None)\n",
    "            \n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op = evaluate(output, y)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "    \n",
    "            #save and restore variables to and from checkpoints.\n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #\n",
    "            summary_writer = tf.summary.FileWriter(log_files_path+'multi_layer/', sess.graph)\n",
    "        \n",
    "            #initialization of all the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "        \n",
    "            #will work with this later\n",
    "            #saver.restore(sess, log_files_path+'multi_layer/model-checkpoint-66000')\n",
    "            \n",
    "            loss_trace = []\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "\n",
    "                    minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "                    loss_trace.append(1-accuracy)    \n",
    "                    print(\"Epoch:\", '%03d' % epoch, \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "                        \n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    saver.save(sess, log_files_path + 'multi_layer/model-checkpoint', global_step=global_step)\n",
    "                        \n",
    "            print(\"Optimization Finished!\")\n",
    "            #accuracy evaluated with the whole test dataset\n",
    "            accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            print(\"Test Accuracy:\", accuracy)\n",
    "                    \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Execution time (seconds) was %0.3f' % elapsed_time)\n",
    "            \n",
    "            # Visualization of the results\n",
    "            # loss function\n",
    "            plt.plot(loss_trace)\n",
    "            plt.title('Cross Entropy Loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
