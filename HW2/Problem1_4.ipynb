{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Impact of different number of layers, different activation functions and optimization on learning): \n",
    "The code logistic_regression_multi_layer.ipynb is a 2-layer logistic regression. The goal is to extend it to 4- & 6-layer logistic regression with different neurons and activation function for each layer utilizing different optimization routine to assess their impact on accuracy.\n",
    "- (4) 4 layers all sigmoid\n",
    "- In all those cases, what is the exact number of parameters we are trying to learn? Assess and conclude\n",
    "- 784$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$50 + 50 + 50$\\times$10 + 10 = 44860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-1-af67203b0711>:9: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#load MNIST dataset \n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "learning_rate = 0.05\n",
    "training_epochs = 100\n",
    "batch_size = 50\n",
    "display_step = 10\n",
    "\n",
    "#Network Architecture\n",
    "# -----------------------------------------\n",
    "# Three hidden layers\n",
    "# ------------------------------------------\n",
    "# number of neurons in layer 1\n",
    "n_hidden_1 = 50\n",
    "# number of neurons in layer 2\n",
    "n_hidden_2 = 50\n",
    "# number of neurons in layer 3\n",
    "n_hidden_3 = 50\n",
    "\n",
    "#MNIST data image of shape 28*28=784\n",
    "input_size = 784\n",
    "\n",
    "# 0-9 digits recognition (labels)\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape of the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    # comes from the study by He et al. for ReLU layers\n",
    "    w_std = (2.0/weight_shape[0])**0.5\n",
    "    #print(weight_shape[0])\n",
    "    #w_std = 0.5;\n",
    "\n",
    "    #initialization of the weights\n",
    "    #you can try either\n",
    "    w_0 = tf.random_normal_initializer(stddev=w_std)\n",
    "    #w_0 = tf.random_uniform_initializer(minval=-1,maxval=1)\n",
    "\n",
    "    b_0 = tf.constant_initializer(value=0)\n",
    "    \n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_0)\n",
    "    b = tf.get_variable(\"b\", bias_shape,   initializer=b_0)\n",
    "    \n",
    "    #print('Weight Matrix:', W)\n",
    "    #print('Bias Vector:', b)\n",
    "    # sigmoid activation\n",
    "    return tf.nn.sigmoid(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    \"\"\"\n",
    "    define the whole network (3 hidden layers + output layers)\n",
    "    input:\n",
    "        - a batch of pictures \n",
    "        (input shape = (batch_size*image_size))\n",
    "    output:\n",
    "        - a batch vector corresponding to the logits predicted by the network\n",
    "        (output shape = (batch_size*output_size)) \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_layer_1\"):\n",
    "        hidden_1 = layer(x, [input_size, n_hidden_1], [n_hidden_1])\n",
    "        print([input_size, n_hidden_1])\n",
    "     \n",
    "    with tf.variable_scope(\"hidden_layer_2\"):\n",
    "        hidden_2 = layer(hidden_1, [n_hidden_1, n_hidden_2], [n_hidden_2])\n",
    "        print([n_hidden_1, n_hidden_2])\n",
    "\n",
    "    with tf.variable_scope(\"hidden_layer_3\"):\n",
    "        hidden_3 = layer(hidden_2, [n_hidden_2, n_hidden_3], [n_hidden_3])\n",
    "        print([n_hidden_2, n_hidden_3])\n",
    "     \n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_3, [n_hidden_3, output_size], [output_size])\n",
    "        print([n_hidden_3, output_size])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_1(output, y):\n",
    "    \"\"\"\n",
    "    computes the average error per data sample \n",
    "    by computing the cross-entropy loss over a minibatch\n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    dot_product = y * tf.log(output)\n",
    "    \n",
    "    #tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "    xentropy = -tf.reduce_sum(dot_product, 1)\n",
    "    \n",
    "    #tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_2(output, y):\n",
    "    \"\"\"\n",
    "    Computes softmax cross entropy between logits and labels and then the loss \n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #mean square error\n",
    "    #loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-output)))\n",
    "    \n",
    "    #Computes softmax cross entropy between logits and labels.\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    # tf.train.AdamOptimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -y: true value for the validation set\n",
    "    output:\n",
    "        - accuracy: accuracy on the validation set (scalar between 0 and 1)\n",
    "    \"\"\"\n",
    "    #correct prediction is a binary vector which equals one when the output and y match\n",
    "    #otherwise the vector equals 0\n",
    "    #tf.cast: change the type of a tensor into another one (改变张量数据类型的转换函数)\n",
    "    #then, by taking the mean of the tensor, we directly have the average score, so the accuracy\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 50]\n",
      "[50, 50]\n",
      "[50, 50]\n",
      "[50, 10]\n",
      "WARNING:tensorflow:From <ipython-input-5-ca3425cd9455>:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 000 cost function= 1.7293085  Validation Error: 0.46480000019073486\n",
      "Epoch: 010 cost function= 1.5965682  Validation Error: 0.1850000023841858\n",
      "Epoch: 020 cost function= 1.5870444  Validation Error: 0.2070000171661377\n",
      "Epoch: 030 cost function= 1.6075910  Validation Error: 0.18779999017715454\n",
      "Epoch: 040 cost function= 1.6103945  Validation Error: 0.20179998874664307\n",
      "Epoch: 050 cost function= 1.6203009  Validation Error: 0.21139997243881226\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 060 cost function= 1.6443307  Validation Error: 0.2871999740600586\n",
      "Epoch: 070 cost function= 1.6176011  Validation Error: 0.21420001983642578\n",
      "Epoch: 080 cost function= 1.6381560  Validation Error: 0.26080000400543213\n",
      "Epoch: 090 cost function= 1.6518717  Validation Error: 0.23820000886917114\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.7708\n",
      "Execution time (seconds) was 324.335\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #please, make sure you changed for your own path \n",
    "    log_files_path = 'D:/JupyterNotebook/IEOR_4742/HW2/logs/'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        with tf.variable_scope(\"multi_layer\"):\n",
    "            #neural network definition \n",
    "            \n",
    "            #the input variables are first defined as placeholder \n",
    "            #a placeholder is a variable/data which will be assigned later \n",
    "            #image vector & label\n",
    "            x = tf.placeholder(\"float\", [None, input_size])   # MNIST data image of shape 28*28=784\n",
    "            y = tf.placeholder(\"float\", [None, output_size])  # 0-9 digits recognition\n",
    "\n",
    "            #the network is defined using the inference function defined above in the code\n",
    "            output = inference(x)\n",
    "\n",
    "            cost = loss_2(output, y)\n",
    "            \n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            train_op = training(cost, global_step)\n",
    "            #train_op = training(cost, global_step=None)\n",
    "            \n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op = evaluate(output, y)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "    \n",
    "            #save and restore variables to and from checkpoints.\n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #\n",
    "            summary_writer = tf.summary.FileWriter(log_files_path+'multi_layer/', sess.graph)\n",
    "        \n",
    "            #initialization of all the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "        \n",
    "            #will work with this later\n",
    "            #saver.restore(sess, log_files_path+'multi_layer/model-checkpoint-66000')\n",
    "            \n",
    "            loss_trace = []\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "\n",
    "                    minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "                    loss_trace.append(1-accuracy)    \n",
    "                    print(\"Epoch:\", '%03d' % epoch, \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "                        \n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    saver.save(sess, log_files_path + 'multi_layer/model-checkpoint', global_step=global_step)\n",
    "                        \n",
    "            print(\"Optimization Finished!\")\n",
    "            #accuracy evaluated with the whole test dataset\n",
    "            accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            print(\"Test Accuracy:\", accuracy)\n",
    "                    \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Execution time (seconds) was %0.3f' % elapsed_time)\n",
    "            \n",
    "            # Visualization of the results\n",
    "            # loss function\n",
    "            plt.plot(loss_trace)\n",
    "            plt.title('Cross Entropy Loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
