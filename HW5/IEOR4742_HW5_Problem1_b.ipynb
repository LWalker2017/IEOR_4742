{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "IEOR4742_HW5_Problem1_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3FxUGBY1a9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0 # GPU Version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-02T12:44:09.131674Z",
          "start_time": "2018-10-02T12:44:09.129175Z"
        },
        "id": "e2QDid2a1PQ9",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.310842Z",
          "start_time": "2018-10-03T22:05:10.381461Z"
        },
        "id": "x7iW4nGV1PQ-",
        "colab_type": "code",
        "outputId": "503c1175-0e28-4055-c652-2ba77910818f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from pathlib import Path\n",
        "import argparse\n",
        "# %matplotlib inline\n",
        "plt.rcParams['savefig.dpi'] = 159.1 #图片像素\n",
        "plt.rcParams['figure.dpi'] = 159.1  #分辨率:512*512\n",
        "\n",
        "# check tensorflow version\n",
        "print(tf.__version__)\n",
        "# Confirm tensorflow can see the GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6e4FxJ21PRF",
        "colab_type": "text"
      },
      "source": [
        "# Definition of the Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.324885Z",
          "start_time": "2018-10-03T22:05:26.313169Z"
        },
        "id": "Ouj4HHNi1PRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Following Hinton-Salakhutdinov Architecture\n",
        "\n",
        "# 3 hidden layers for encoder\n",
        "n_encoder_h_1 = 1000\n",
        "n_encoder_h_2 = 500\n",
        "n_encoder_h_3 = 250\n",
        "\n",
        "# 3 hidden layers for decoder\n",
        "n_decoder_h_1 = 250\n",
        "n_decoder_h_2 = 500\n",
        "n_decoder_h_3 = 1000\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "training_epochs = 1000\n",
        "batch_size = 64\n",
        "display_step = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUiM8Ltl1PRJ",
        "colab_type": "text"
      },
      "source": [
        "# Batch Normalization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.435086Z",
          "start_time": "2018-10-03T22:05:26.382374Z"
        },
        "id": "Qdz3YLCo1PRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer_batch_normalization(x, n_out, phase_train):\n",
        "    \"\"\"\n",
        "    Defines the network layers\n",
        "    input:\n",
        "        - x: input vector of the layer\n",
        "        - n_out: integer, depth of input maps - number of sample in the batch \n",
        "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
        "    output:\n",
        "        - batch-normalized maps   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
        "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
        "    \n",
        "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
        "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
        "\n",
        "    #tf.nn.moment: https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
        "    #calculate mean and variance of x\n",
        "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
        "    \n",
        "    #tf.train.ExponentialMovingAverage:\n",
        "    #https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
        "    #Maintains moving averages of variables by employing an exponential decay.\n",
        "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
        "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
        "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
        "    \n",
        "    def mean_var_with_update():\n",
        "        with tf.control_dependencies([ema_apply_op]):\n",
        "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
        "        \n",
        "    #tf.cond: https://www.tensorflow.org/api_docs/python/tf/cond\n",
        "    #Return true_fn() if the predicate pred is true else false_fn()\n",
        "    mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
        "\n",
        "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
        "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
        "    \n",
        "    return tf.reshape(normed, [-1, n_out])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz6kNaEl1PRO",
        "colab_type": "text"
      },
      "source": [
        "# Definition of the Layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.461121Z",
          "start_time": "2018-10-03T22:05:26.444649Z"
        },
        "id": "YDjhGajP1PRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer(x, weight_shape, bias_shape, phase_train):\n",
        "    \n",
        "    \"\"\"\n",
        "    Defines the network layers\n",
        "    input:\n",
        "        - x: input vector of the layer\n",
        "        - weight_shape: shape of the weight maxtrix\n",
        "        - bias_shape: shape of the bias vector\n",
        "        - phase_train: boolean tf.Variable, true indicates training phase\n",
        "    output:\n",
        "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
        "    \"\"\"\n",
        "    \n",
        "    #initialize weights\n",
        "    weight_init = tf.random_normal_initializer(stddev=(1.0/weight_shape[0])**0.5)\n",
        "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
        "    \n",
        "    bias_init = tf.constant_initializer(value=0)\n",
        "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
        "\n",
        "    logits = tf.matmul(x, W) + b\n",
        "    \n",
        "    #apply the non-linear function after the batch normalization\n",
        "    return tf.nn.sigmoid(layer_batch_normalization(logits, weight_shape[1], phase_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-02T13:39:04.039484Z",
          "start_time": "2018-10-02T13:39:04.036698Z"
        },
        "id": "P8BD3gw11PRS",
        "colab_type": "text"
      },
      "source": [
        "# Definition of the Encoder Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.484126Z",
          "start_time": "2018-10-03T22:05:26.463872Z"
        },
        "id": "TCF8n-xZ1PRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(x, n_code, phase_train):\n",
        "    \n",
        "    \"\"\"\n",
        "    Defines the network encoder part\n",
        "    input:\n",
        "        - x: input vector of the encoder\n",
        "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder)\n",
        "        - phase_train: boolean tf.Variable, true indicates training phase\n",
        "    output:\n",
        "        - output vector: reduced dimension\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.variable_scope(\"encoder\"):\n",
        "        \n",
        "        with tf.variable_scope(\"h_1\"):\n",
        "            h_1 = layer(x, [262144, n_encoder_h_1], [n_encoder_h_1], phase_train)\n",
        "\n",
        "        with tf.variable_scope(\"h_2\"):\n",
        "            h_2 = layer(h_1, [n_encoder_h_1, n_encoder_h_2], [n_encoder_h_2], phase_train)\n",
        "\n",
        "        with tf.variable_scope(\"h_3\"):\n",
        "            h_3 = layer(h_2, [n_encoder_h_2, n_encoder_h_3], [n_encoder_h_3], phase_train)\n",
        "\n",
        "        with tf.variable_scope(\"code\"):\n",
        "            output = layer(h_3, [n_encoder_h_3, n_code], [n_code], phase_train)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-02T13:39:56.962874Z",
          "start_time": "2018-10-02T13:39:56.960040Z"
        },
        "id": "-pYcCvYl1PRX",
        "colab_type": "text"
      },
      "source": [
        "# Definition of the Decoder Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.504557Z",
          "start_time": "2018-10-03T22:05:26.486050Z"
        },
        "id": "GwZpWBs01PRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(x, n_code, phase_train):\n",
        "    \"\"\"\n",
        "    Defines the network decoder part\n",
        "    input:\n",
        "        - x: input vector of the decoder - reduced dimension vector\n",
        "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder) \n",
        "        - phase_train: boolean tf.Variable, true indicates training phase\n",
        "    output:\n",
        "        - output vector: reconstructed dimension of the initial vector\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.variable_scope(\"decoder\"):\n",
        "        \n",
        "        with tf.variable_scope(\"h_1\"):\n",
        "            h_1 = layer(x, [n_code, n_decoder_h_1], [n_decoder_h_1], phase_train)\n",
        "\n",
        "        with tf.variable_scope(\"h_2\"):\n",
        "            h_2 = layer(h_1, [n_decoder_h_1, n_decoder_h_2], [n_decoder_h_2], phase_train)\n",
        "\n",
        "        with tf.variable_scope(\"h_3\"):\n",
        "            h_3 = layer(h_2, [n_decoder_h_2, n_decoder_h_3], [n_decoder_h_3], phase_train)\n",
        "\n",
        "        with tf.variable_scope(\"output\"):\n",
        "            output = layer(h_3, [n_decoder_h_3, 262144], [262144], phase_train)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-02T13:40:11.932837Z",
          "start_time": "2018-10-02T13:40:11.929439Z"
        },
        "id": "cxl1fxfM1PRd",
        "colab_type": "text"
      },
      "source": [
        "# Definition of the Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.517979Z",
          "start_time": "2018-10-03T22:05:26.506902Z"
        },
        "id": "aFoemz8p1PRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(output, x):\n",
        "    \"\"\"\n",
        "    Compute the loss of the auto-encoder\n",
        "    \n",
        "    intput:\n",
        "        - output: the output of the decoder\n",
        "        - x: true value of the sample batch - this is the input of the encoder\n",
        "        \n",
        "        the two have the same shape (batch_size * num_of_classes)\n",
        "    output:\n",
        "        - loss: loss of the corresponding batch (scalar tensor)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.variable_scope(\"training\"):\n",
        "        \n",
        "        l2 = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x)), 1))\n",
        "        train_loss = tf.reduce_mean(l2)\n",
        "        train_summary_op = tf.summary.scalar(\"train_cost\", train_loss)\n",
        "        return train_loss, train_summary_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ktv9jzz1PRi",
        "colab_type": "text"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.531705Z",
          "start_time": "2018-10-03T22:05:26.520900Z"
        },
        "id": "hv28QIpv1PRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(cost, global_step):\n",
        "    \"\"\"\n",
        "    defines the necessary elements to train the network\n",
        "    \n",
        "    intput:\n",
        "        - cost: the cost is the loss of the corresponding batch\n",
        "        - global_step: number of batch seen so far, it is incremented by one \n",
        "        each time the .minimize() function is called\n",
        "    \"\"\"\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "    return train_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2BD72eV1PRm",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.558495Z",
          "start_time": "2018-10-03T22:05:26.534046Z"
        },
        "id": "_9i_mIt61PRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(output, x):\n",
        "    \"\"\"\n",
        "    evaluates the accuracy on the validation set \n",
        "    input:\n",
        "        -output: prediction vector of the network for the validation set\n",
        "        -x: true value for the validation set\n",
        "    output:\n",
        "        - val_loss: loss of the autoencoder\n",
        "        - in_image_op: input image \n",
        "        - out_image_op: reconstructed image \n",
        "        - val_summary_op: summary of the loss\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.variable_scope(\"validation\"):\n",
        "        \n",
        "        in_image_op = image_summary(\"input_image\", x)\n",
        "        \n",
        "        out_image_op = image_summary(\"output_image\", output)\n",
        "        \n",
        "        l2_norm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x, name=\"val_diff\")), 1))\n",
        "        \n",
        "        val_loss = tf.reduce_mean(l2_norm)\n",
        "        \n",
        "        val_summary_op = tf.summary.scalar(\"val_cost\", val_loss)\n",
        "        \n",
        "        return val_loss, in_image_op, out_image_op, val_summary_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-02T13:41:48.805072Z",
          "start_time": "2018-10-02T13:41:48.802014Z"
        },
        "id": "ep9kvOAt1PRq",
        "colab_type": "text"
      },
      "source": [
        "# Image Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:05:26.571265Z",
          "start_time": "2018-10-03T22:05:26.564897Z"
        },
        "id": "StYbRZfU1PRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_summary(label, tensor):\n",
        "    #tf.summary.image: https://www.tensorflow.org/api_docs/python/tf/summary/image\n",
        "    #Outputs a Summary protocol buffer with images.\n",
        "\n",
        "    tensor_reshaped = tf.reshape(tensor, [-1, 512, 512, 1])\n",
        "    return tf.summary.image(label, tensor_reshaped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofTgUV_K1PRy",
        "colab_type": "text"
      },
      "source": [
        "# Plotting samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJALzyxx1PRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_sample(samples, size1, size2):\n",
        "    \n",
        "    fig1 = plt.figure(figsize=(size1, size2))\n",
        "    gs = gridspec.GridSpec(size1, size2)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(sample.reshape(512, 512), cmap='gray')\n",
        "        # plt.imshow(sample.reshape(28, 28), cmap='gray')\n",
        "\n",
        "    return fig1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EHon4Kr1PR2",
        "colab_type": "text"
      },
      "source": [
        "# Faciliate the path defining process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m1zPJmO1PR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Though it's not possible to get the path to the notebook by __file__, os.path is still very useful in dealing with paths and files\n",
        "# In this case, we can use an alternative: pathlib.Path\n",
        "\"\"\"\n",
        "code_dir   = os.path.dirname(__file__)\n",
        "\"\"\"\n",
        "#get the current path of our code\n",
        "code_dir = Path().resolve()\n",
        "#create output_dir within the same path\n",
        "output_dir = os.path.join(code_dir, 'Problem1_b_1/')\n",
        "if not os.path.isdir(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnqeY0Y61PR5",
        "colab_type": "text"
      },
      "source": [
        "# Use all images with random shuffling for training the Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObADdM_u1PR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def next_batch(data, num):\n",
        "    '''\n",
        "    Return a total of `num` random samples \n",
        "    '''\n",
        "    #print(len(data))\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = np.array([data[i] for i in idx])\n",
        "\n",
        "    return data_shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eooHgz-1PR9",
        "colab_type": "text"
      },
      "source": [
        "# Read image file from given path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cYc_ycI1PR9",
        "colab_type": "code",
        "outputId": "838fd250-01fb-4963-8dff-ebc3c8a02f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sizePixel1 = 512\n",
        "sizePixel2 = sizePixel1*sizePixel1\n",
        "size_d = 32\n",
        "\n",
        "def read_tensor_from_image_file(path, input_height=sizePixel1, input_width=sizePixel1, input_mean=0, input_std=255):\n",
        "    \n",
        "    input_name = \"file_reader\"\n",
        "    output_name = \"normalized\"\n",
        "    file_reader = tf.read_file(path, input_name)\n",
        "    image_reader = tf.image.decode_png(file_reader, channels = 1)\n",
        "    float_caster = tf.cast(image_reader, tf.float32)\n",
        "    dims_expander = tf.expand_dims(float_caster, 0);\n",
        "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
        "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
        "    sess = tf.Session()\n",
        "    result = sess.run(normalized)\n",
        "    return result \n",
        "\n",
        "\n",
        "nSeries = 222\n",
        "numInSeries = 1\n",
        "nImages = nSeries*numInSeries #222\n",
        "img  = np.zeros((nImages, sizePixel1*sizePixel1))\n",
        "counter = 0\n",
        "\n",
        "#get the current path of our code\n",
        "folder = Path().resolve()\n",
        "\n",
        "for j in range(0,numInSeries):\n",
        "    for i in range(1,nSeries+1):\n",
        "        # print(counter,i,j)\n",
        "        fname = str(i) + '_' + str(j) + '.png'\n",
        "        path = './data/' + fname\n",
        "        orig_img = read_tensor_from_image_file(path)\n",
        "        # vectorize\n",
        "        img[counter] = orig_img.reshape(-1)\n",
        "        \n",
        "        # original size\n",
        "        # img[counter] = orig_img.reshape(sizePixel1,sizePixel1)\n",
        "        counter = counter+1\n",
        "\n",
        "print('Input image shape is:', img.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input image shape is: (222, 262144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-02T13:51:07.293398Z",
          "start_time": "2018-10-02T13:51:07.282274Z"
        },
        "id": "DuvFrISc1PSC",
        "colab_type": "text"
      },
      "source": [
        "# Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-03T22:07:06.083741Z",
          "start_time": "2018-10-03T22:05:26.575512Z"
        },
        "scrolled": false,
        "id": "YbWv3_o81PSD",
        "colab_type": "code",
        "outputId": "f37e42bd-f7b9-40ed-8437-3760f4311ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    #if a python file, please use the 4 lines bellow and comment the \"n_code = '1'\"\n",
        "    #parser = argparse.ArgumentParser(description='Autoencoder')\n",
        "    #parser.add_argument('n_code', nargs=1, type=str)\n",
        "    #args = parser.parse_args(['--help'])\n",
        "    #n_code = args.n_code[0]\n",
        "    \n",
        "    #if a jupyter file, please comment the 4 above and use the one bellow\n",
        "    n_code = '2'\n",
        "    \n",
        "    #feel free to change with your own \n",
        "    #log_files_path = './autoencoder_logs/'\n",
        "\n",
        "    with tf.Graph().as_default():\n",
        "\n",
        "        with tf.variable_scope(\"autoencoder_model\"):\n",
        "\n",
        "            #the input variables are first define as placeholder \n",
        "            # a placeholder is a variable/data which will be assigned later \n",
        "            # image vector & label, phase_train is a boolean \n",
        "            x = tf.placeholder(\"float\", [None, 262144]) # MNIST data image of shape 512*512=262144\n",
        "            \n",
        "            phase_train = tf.placeholder(tf.bool)\n",
        "            \n",
        "            #define the encoder \n",
        "            code = encoder(x, int(n_code), phase_train)\n",
        "            \n",
        "            #define the decoder\n",
        "            output = decoder(code, int(n_code), phase_train)\n",
        "            \n",
        "            #compute the loss \n",
        "            cost, train_summary_op = loss(output, x)\n",
        "\n",
        "            #initialize the value of the global_step variable \n",
        "            # recall: it is incremented by one each time the .minimise() is called\n",
        "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "\n",
        "            train_op = training(cost, global_step)\n",
        "\n",
        "            #evaluate the accuracy of the network (done on a validation set)\n",
        "            eval_op, in_image_op, out_image_op, val_summary_op = evaluate(output, x)\n",
        "\n",
        "            summary_op = tf.summary.merge_all()\n",
        "\n",
        "            #save and restore variables to and from checkpoints.\n",
        "            #saver = tf.train.Saver(max_to_keep=200)\n",
        "\n",
        "            #defines a session\n",
        "            sess = tf.Session()\n",
        "\n",
        "            # summary writer\n",
        "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
        "            #train_writer = tf.summary.FileWriter(log_files_path + 'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
        "\n",
        "            #val_writer   = tf.summary.FileWriter(log_files_path + 'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
        "\n",
        "            #initialization of the variables\n",
        "            init_op = tf.global_variables_initializer()\n",
        "\n",
        "            sess.run(init_op)\n",
        "\n",
        "            # Training cycle\n",
        "            for epoch in range(training_epochs):\n",
        "\n",
        "                avg_cost = 0.\n",
        "                total_batch = int(len(img)/batch_size)\n",
        "                \n",
        "                # Loop over all batches\n",
        "                for i in range(total_batch):\n",
        "                    \n",
        "                    # minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
        "                    minibatch_x = next_batch(img, batch_size)\n",
        "                    \n",
        "                    # Fit training using batch data\n",
        "                    #the training is done using the training dataset\n",
        "                    _, new_cost, train_summary = sess.run([train_op, cost, train_summary_op], feed_dict={x: minibatch_x, phase_train: True})\n",
        "                    \n",
        "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
        "                    \n",
        "                    # Compute average loss\n",
        "                    avg_cost += new_cost/total_batch\n",
        "                \n",
        "                # Display logs per epoch step\n",
        "                if epoch % display_step == 0:\n",
        "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
        "\n",
        "                    #the accuracy is evaluated using the validation dataset\n",
        "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
        "\n",
        "#                     validation_loss, in_image, out_image, val_summary = sess.run([eval_op, in_image_op, out_image_op, val_summary_op], feed_dict={x: mnist.validation.images, phase_train: False})\n",
        "#                     val_writer.add_summary(in_image, sess.run(global_step))\n",
        "#                     val_writer.add_summary(out_image, sess.run(global_step))\n",
        "#                     val_writer.add_summary(val_summary, sess.run(global_step))\n",
        "#                     print(\"Validation Loss:\", validation_loss)\n",
        "\n",
        "                    #save to use later\n",
        "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
        "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
        "                    #saver.save(sess, log_files_path + 'mnist_autoencoder_hidden_' + n_code + '_logs/model-checkpoint-' + '%04d' % (epoch+1), global_step=global_step)\n",
        "\n",
        "\n",
        "            print(\"Optimization Finished!\")\n",
        "            \n",
        "            # generate new image sets\n",
        "            out_image = sess.run([output], feed_dict={x: img, phase_train: False})\n",
        "            # extract np.array from the list\n",
        "            out_image = out_image[0]\n",
        "            \n",
        "            for k in range(1, len(img)+1):\n",
        "                # size1 = 5\n",
        "                # size2 = 5\n",
        "                # fig1 = plot_sample(out_image[k-1], size1, size2)\n",
        "                # plt.savefig(output_dir + str(k) + '_1.png', bbox_inches='tight')\n",
        "                # plt.close(fig1)\n",
        "                plt.figure(\"Image\", frameon=False)  # figure window name\n",
        "                plt.imshow(out_image[k-1].reshape(512, 512), cmap='gray')\n",
        "                plt.axis('off')\n",
        "                plt.savefig(output_dir + str(k) + '_1.png', bbox_inches='tight')\n",
        "                plt.close()\n",
        "                \n",
        "            print(\"Generate New Image Sets Done!\")\n",
        "                \n",
        "            test_loss = sess.run(eval_op, feed_dict={x: img, phase_train: False})\n",
        "            \n",
        "            print()\n",
        "            print(\"Test Loss:\", test_loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-bc7ece62fad9>:14: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Epoch: 0001 cost = 270.932159424\n",
            "Epoch: 0011 cost = 239.549647013\n",
            "Epoch: 0021 cost = 236.443674723\n",
            "Epoch: 0031 cost = 235.222193400\n",
            "Epoch: 0041 cost = 232.802027384\n",
            "Epoch: 0051 cost = 232.921498617\n",
            "Epoch: 0061 cost = 229.518051147\n",
            "Epoch: 0071 cost = 229.694173177\n",
            "Epoch: 0081 cost = 227.714172363\n",
            "Epoch: 0091 cost = 226.836471558\n",
            "Epoch: 0101 cost = 229.611419678\n",
            "Epoch: 0111 cost = 227.508178711\n",
            "Epoch: 0121 cost = 226.420934041\n",
            "Epoch: 0131 cost = 225.952484131\n",
            "Epoch: 0141 cost = 226.124755859\n",
            "Epoch: 0151 cost = 225.899490356\n",
            "Epoch: 0161 cost = 224.288162231\n",
            "Epoch: 0171 cost = 222.802444458\n",
            "Epoch: 0181 cost = 224.277928670\n",
            "Epoch: 0191 cost = 221.604217529\n",
            "Epoch: 0201 cost = 219.751683553\n",
            "Epoch: 0211 cost = 220.336222331\n",
            "Epoch: 0221 cost = 221.275187174\n",
            "Epoch: 0231 cost = 222.362767537\n",
            "Epoch: 0241 cost = 220.645217896\n",
            "Epoch: 0251 cost = 220.741861979\n",
            "Epoch: 0261 cost = 220.597941081\n",
            "Epoch: 0271 cost = 218.731892904\n",
            "Epoch: 0281 cost = 218.593327840\n",
            "Epoch: 0291 cost = 216.640345256\n",
            "Epoch: 0301 cost = 218.707890828\n",
            "Epoch: 0311 cost = 219.115071615\n",
            "Epoch: 0321 cost = 217.859456380\n",
            "Epoch: 0331 cost = 214.420288086\n",
            "Epoch: 0341 cost = 216.575673421\n",
            "Epoch: 0351 cost = 216.978998820\n",
            "Epoch: 0361 cost = 214.973256429\n",
            "Epoch: 0371 cost = 214.847254435\n",
            "Epoch: 0381 cost = 213.993306478\n",
            "Epoch: 0391 cost = 215.427795410\n",
            "Epoch: 0401 cost = 214.864247640\n",
            "Epoch: 0411 cost = 214.221694946\n",
            "Epoch: 0421 cost = 213.978190104\n",
            "Epoch: 0431 cost = 210.455663045\n",
            "Epoch: 0441 cost = 217.618555705\n",
            "Epoch: 0451 cost = 212.196161906\n",
            "Epoch: 0461 cost = 211.927337646\n",
            "Epoch: 0471 cost = 210.851023356\n",
            "Epoch: 0481 cost = 209.149617513\n",
            "Epoch: 0491 cost = 209.707611084\n",
            "Epoch: 0501 cost = 210.187520345\n",
            "Epoch: 0511 cost = 214.772338867\n",
            "Epoch: 0521 cost = 210.577977498\n",
            "Epoch: 0531 cost = 207.925170898\n",
            "Epoch: 0541 cost = 210.892517090\n",
            "Epoch: 0551 cost = 211.743316650\n",
            "Epoch: 0561 cost = 208.857325236\n",
            "Epoch: 0571 cost = 206.211013794\n",
            "Epoch: 0581 cost = 207.160730998\n",
            "Epoch: 0591 cost = 209.045572917\n",
            "Epoch: 0601 cost = 209.232376099\n",
            "Epoch: 0611 cost = 207.255716960\n",
            "Epoch: 0621 cost = 206.331609090\n",
            "Epoch: 0631 cost = 210.688385010\n",
            "Epoch: 0641 cost = 208.937795003\n",
            "Epoch: 0651 cost = 211.440561930\n",
            "Epoch: 0661 cost = 206.485473633\n",
            "Epoch: 0671 cost = 208.254562378\n",
            "Epoch: 0681 cost = 206.185857137\n",
            "Epoch: 0691 cost = 209.598968506\n",
            "Epoch: 0701 cost = 206.275746663\n",
            "Epoch: 0711 cost = 202.791885376\n",
            "Epoch: 0721 cost = 199.657460531\n",
            "Epoch: 0731 cost = 205.922932943\n",
            "Epoch: 0741 cost = 202.724395752\n",
            "Epoch: 0751 cost = 206.362548828\n",
            "Epoch: 0761 cost = 202.631734212\n",
            "Epoch: 0771 cost = 204.177739461\n",
            "Epoch: 0781 cost = 198.057718913\n",
            "Epoch: 0791 cost = 202.822118123\n",
            "Epoch: 0801 cost = 196.404693604\n",
            "Epoch: 0811 cost = 202.898956299\n",
            "Epoch: 0821 cost = 199.582753499\n",
            "Epoch: 0831 cost = 197.932993571\n",
            "Epoch: 0841 cost = 206.662017822\n",
            "Epoch: 0851 cost = 202.059173584\n",
            "Epoch: 0861 cost = 196.466883341\n",
            "Epoch: 0871 cost = 201.949218750\n",
            "Epoch: 0881 cost = 196.623550415\n",
            "Epoch: 0891 cost = 196.632029215\n",
            "Epoch: 0901 cost = 200.017527262\n",
            "Epoch: 0911 cost = 199.571685791\n",
            "Epoch: 0921 cost = 198.584203084\n",
            "Epoch: 0931 cost = 194.092330933\n",
            "Epoch: 0941 cost = 200.505905151\n",
            "Epoch: 0951 cost = 193.390472412\n",
            "Epoch: 0961 cost = 196.101272583\n",
            "Epoch: 0971 cost = 197.844889323\n",
            "Epoch: 0981 cost = 194.848195394\n",
            "Epoch: 0991 cost = 194.364542643\n",
            "Optimization Finished!\n",
            "Generate New Image Sets Done!\n",
            "\n",
            "Test Loss: 193.52463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ3hByKJ1PSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.rcParams['savefig.dpi'] = 159.1 #图片像素\n",
        "# plt.rcParams['figure.dpi'] = 159.1  #分辨率\n",
        "# plt.figure(\"Image\", frameon=False)  # figure window name\n",
        "# plt.imshow(out_image[52].reshape(512, 512), cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.savefig(output_dir + 'TEST_1.png', bbox_inches='tight')\n",
        "# plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMQ01M_81PSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a464785-6f39-416e-e152-cc6e3bd35c4f"
      },
      "source": [
        "!zip -r /content/Problem1_b_1.zip /content/Problem1_b_1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/Problem1_b_1/ (stored 0%)\n",
            "  adding: content/Problem1_b_1/17_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/204_1.png (deflated 6%)\n",
            "  adding: content/Problem1_b_1/135_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/168_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/176_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/100_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/5_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/87_1.png (deflated 5%)\n",
            "  adding: content/Problem1_b_1/138_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/46_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/88_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/188_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/195_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/3_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/34_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/183_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/10_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/133_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/102_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/94_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/32_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/153_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/97_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/125_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/51_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/91_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/211_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/6_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/63_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/174_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/60_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/150_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/9_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/55_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/95_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/90_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/200_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/201_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/190_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/43_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/79_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/7_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/171_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/50_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/126_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/71_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/206_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/42_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/222_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/127_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/23_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/59_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/163_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/54_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/132_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/175_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/194_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/62_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/148_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/214_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/64_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/184_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/12_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/30_1.png (deflated 5%)\n",
            "  adding: content/Problem1_b_1/39_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/178_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/44_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/212_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/18_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/130_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/48_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/182_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/131_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/118_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/70_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/2_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/172_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/15_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/129_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/113_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/58_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/67_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/61_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/191_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/136_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/69_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/16_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/21_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/103_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/13_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/134_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/123_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/162_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/78_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/186_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/155_1.png (deflated 6%)\n",
            "  adding: content/Problem1_b_1/185_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/213_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/147_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/108_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/173_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/198_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/75_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/152_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/110_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/202_1.png (deflated 7%)\n",
            "  adding: content/Problem1_b_1/53_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/93_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/85_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/86_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/205_1.png (deflated 7%)\n",
            "  adding: content/Problem1_b_1/14_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/74_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/143_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/187_1.png (deflated 5%)\n",
            "  adding: content/Problem1_b_1/105_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/124_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/106_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/33_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/216_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/119_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/1_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/84_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/4_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/101_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/189_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/47_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/193_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/20_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/156_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/215_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/161_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/29_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/144_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/96_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/197_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/68_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/149_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/76_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/170_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/112_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/27_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/217_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/111_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/218_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/80_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/181_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/104_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/199_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/166_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/209_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/122_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/167_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/72_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/25_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/98_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/192_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/116_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/40_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/164_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/37_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/107_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/219_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/120_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/142_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/57_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/19_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/203_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/109_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/22_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/89_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/45_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/208_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/139_1.png (deflated 5%)\n",
            "  adding: content/Problem1_b_1/99_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/159_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/66_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/145_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/81_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/77_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/154_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/221_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/24_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/8_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/82_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/165_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/141_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/157_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/180_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/207_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/140_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/128_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/38_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/65_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/11_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/115_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/92_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/83_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/220_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/35_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/179_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/31_1.png (deflated 4%)\n",
            "  adding: content/Problem1_b_1/158_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/196_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/36_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/117_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/160_1.png (deflated 5%)\n",
            "  adding: content/Problem1_b_1/28_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/41_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/210_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/121_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/151_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/137_1.png (deflated 3%)\n",
            "  adding: content/Problem1_b_1/177_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/26_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/169_1.png (deflated 1%)\n",
            "  adding: content/Problem1_b_1/114_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/49_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/56_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/52_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/146_1.png (deflated 2%)\n",
            "  adding: content/Problem1_b_1/73_1.png (deflated 2%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-RxrWkSe1_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}